# %%
import os
import yaml
import json
import math
import argparse
import numpy as np
import nibabel as nib
import torch
import torch.cuda
from torchvision import transforms as T

#%%
def start_points(size, split_size, overlap=0):
    points = [0]
    stride = int(split_size * (1-overlap))
    counter = 1
    while True:
        pt = stride * counter
        if pt + split_size >= size:
            points.append(size - split_size)
            break
        else:
            points.append(pt)
        counter += 1
    return points


def get_tiles(h, w,
              hTile,
              wTile,
              overlap):

    '''
    Returns vectors required to sample patches from whole image
    h, w - image height, width
    hTile, wTile - patch height, width
    overlap - value in range [0-1] which stands for overlaying area of
                surrounding patches from 0 to 100% of theirs area
    '''
    X_points = start_points(w, wTile, overlap)
    Y_points = start_points(h, hTile, overlap)

    tiles = np.zeros((len(Y_points)*len(X_points), 6), int)

    k = 0
    for i, y_cord in enumerate(Y_points):
        for j, x_cord in enumerate(X_points):
            # split = image[i:i+hTile, j:j+wTile]
            tiles[k] = (y_cord, x_cord, hTile, wTile, i, j)
            k += 1
    return tiles


def convert_img_to_bag(image, tiles):
        '''
        Utilizes 'tiles' vectors generated by get_tiles function
        Returns set of patches sampled from the whole image
        '''
        hTile = tiles[0][2]
        wTile = tiles[0][3]
        c = image.shape[0]
        img_shape = (len(tiles), c, hTile, wTile)
        new_img = torch.zeros(img_shape)

        for i, tile in enumerate(tiles):
            for channel in range(c):
                new_img[i][channel] = image[channel][tile[0]:tile[0]+tile[2],
                                                     tile[1]:tile[1]+tile[3]]
            
        instances = new_img
        instances_cords = tiles[:, 4:6]

        return instances, instances_cords


def get_site_img_stats(imgs):
    '''
    Returns mean and std of the images
    '''
    img_mean = []
    img_std = []
    
    for img_path in imgs:
        img = np.asarray(nib.load(img_path).dataobj)
        mask = np.asarray(nib.load(mask_path).dataobj)
        
        img_mean.append(img.mean())
        img_std.append(img.std())

    return np.mean(img_mean), np.mean(img_std)


def get_args_parser():
    default = '/home/jr_buler/wmh/config.yml'
    help = '''path to .yml config file
    specyfying datasets/training params'''

    parser = argparse.ArgumentParser()
    parser.add_argument("--config_path", type=str,
                        default=default,
                        help=help)
    return parser

parser = get_args_parser()
args, unknown = parser.parse_known_args()
with open(args.config_path) as file:
    config = yaml.load(file, Loader=yaml.FullLoader)


#%% CONFIG load
# set seed and device
seed = config['seed']
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
device = torch.device(config['device'] if torch.cuda.is_available() else "cpu")
# dataloaders args
train_val_frac = config['data_sets']['split_fraction_train_val']
batch_size = config['training_plan']['parameters']['batch_size']
num_workers = config['data_sets']['num_workers']
class_names = config['data_sets']['class_names']

# image parameters
patch_size = config['data_sets']['patch_size']
overlap_train_val = config['data_sets']['overlap_train_val']
overlap_test = config['data_sets']['overlap_test']

mil_params_train_val = {'patch_size': patch_size,
                        'overlap': overlap_train_val}
mil_params_test = {'patch_size': patch_size,
                   'overlap': overlap_test}

train_dir = config['dir']['train']
test_dir = config['dir']['test']

# %% Search files in the directory
root = train_dir
brain = {"image": [], "mask": [], "brain_mask": []}

for root, dirs, files in os.walk(root, topdown=False):
    for name in files:
        f = os.path.join(root, name)

        if f.__contains__('pre/FLAIR.nii'):
            brain['image'].append(f)
            pth = os.path.join(root, 'brain_mask_bet_mask.nii.gz')
            brain['brain_mask'].append(pth)

        if f.__contains__('wmh.nii'):
            brain['mask'].append(f)

# %% Load images and masks, create patches and save them to the folder
non_zero_indices = []
zero_indices = []
ii = 0
save_path = '/media/dysk_a/jr_buler/WMH/patches'

for i, (img_path, brain_path, mask_path) in enumerate(zip(brain['image'], brain['brain_mask'], brain['mask'])):
    img = np.asarray(nib.load(img_path).dataobj)
    mask = np.asarray(nib.load(mask_path).dataobj)
    brain = np.asarray(nib.load(brain_path).dataobj)

    tiles = get_tiles(img.shape[0],
                      img.shape[1],
                      patch_size,
                      patch_size,
                      overlap=overlap_train_val)

    img = torch.from_numpy(img)
    mask = torch.from_numpy(mask)
    brain = torch.from_numpy(brain)

    img = img.permute(2, 0, 1)    # shape [slice, h, w]
    mask = mask.permute(2, 0, 1)
    brain = brain.permute(2, 0, 1)

    img = torch.mul(img, brain, )
    
    # deleting 'other patology' mask labels
    # mask_bag[mask_bag==2.0] = 0.
    mask[mask==2.0] = 0.

    img_bag, img_coords = convert_img_to_bag(image=img,
                                               tiles=tiles)


    mask_bag, mask_coords = convert_img_to_bag(image=mask,
                                               tiles=tiles)
    
    # patch x slice x h x w -> patch*slice x h x w
    whole_img_bag = img_bag.view(-1, img_bag.shape[2], img_bag.shape[3])
    whole_mask_bag = mask_bag.view(-1, mask_bag.shape[2], mask_bag.shape[3])

    ### Discard patches under certain threshold of non-zero pixels
    patch_idx = []
    patches_to_keep = []
    for patch in range(whole_img_bag.shape[0]):
        if torch.count_nonzero(whole_img_bag[patch, :, :]) >= (0.9*patch_size**2):
            patches_to_keep.append(patch)
   
    patch_idx.append(patches_to_keep)
    whole_img_bag = whole_img_bag[patches_to_keep, :, :]
    whole_mask_bag = whole_mask_bag[patches_to_keep, :, :]
    ### Less memory required for data storage

    for img, mask in zip(whole_img_bag, whole_mask_bag):
        if torch.sum(mask) > 0:
            non_zero_indices.append(ii)
            # Save img patch to folder for non-zero masks
            folder_path = os.path.join(save_path, "non_zero_masks")
            if not os.path.exists(folder_path):
                os.makedirs(folder_path)
            img_path = os.path.join(folder_path, f"img_{ii}.nii.gz")
            mask_path = os.path.join(folder_path, f"mask_{ii}.nii.gz")
            nib.save(nib.Nifti1Image(img.numpy(), np.eye(4)), img_path)
            # nib.save(nib.Nifti1Image(mask.numpy(), np.eye(4)), mask_path)
        else:
            zero_indices.append(ii)
            # Save img patch to folder for zero masks
            folder_path = os.path.join(save_path, "zero_masks")
            if not os.path.exists(folder_path):
                os.makedirs(folder_path)
            img_path = os.path.join(folder_path, f"img_{ii}.nii.gz")
            mask_path = os.path.join(folder_path, f"mask_{ii}.nii.gz")
            nib.save(nib.Nifti1Image(img.numpy(), np.eye(4)), img_path)
            # nib.save(nib.Nifti1Image(mask.numpy(), np.eye(4)), mask_path)
        ii += 1
   
# Save non_zero_indices and zero_indices to JSON file
indices = {
    "non_zero_indices": non_zero_indices,
    "zero_indices": zero_indices
}

json_path = os.path.join(save_path, "bag_info.json")
with open(json_path, "w") as json_file:
    json.dump(indices, json_file)

# %% Create a list to store the bags
save_path = '/media/dysk_a/jr_buler/WMH/patches'
bags = []
num_patches_percentage = []
num_patches = 100
min_percentage = 1  # (1, 100)
max_percentage = 15 # (1, 100)

json_path = os.path.join(save_path, "bag_info.json")
with open(json_path, "r") as json_file:
    indices = json.load(json_file)

non_zero_indices = indices["non_zero_indices"]
zero_indices = indices["zero_indices"]

while sum(num_patches_percentage) < len(non_zero_indices):
    if np.random.rand() < 0.5:
        num_patches_percentage.append(math.ceil(np.random.randint(min_percentage, max_percentage) * num_patches / 100))
    else:
        num_patches_percentage.append(0)

if sum(num_patches_percentage) > len(non_zero_indices):
    num_patches_percentage[-1] -= sum(num_patches_percentage) - len(non_zero_indices)

for percentage in num_patches_percentage:
    
    bag = {"image": [], "mask": [], "label": []}

    non_zero_patches = np.random.choice(non_zero_indices, size=percentage, replace=False)
    if percentage != 0:
        non_zero_indices = list(set(non_zero_indices) - set(non_zero_patches))
    for i in non_zero_patches:
        img_path = os.path.join(save_path, "non_zero_masks", f"img_{i}.nii.gz")
        mask_path = os.path.join(save_path, "non_zero_masks", f"mask_{i}.nii.gz")
        label = 1
        bag["image"].append(img_path)
        bag["mask"].append(mask_path)
        bag["label"].append(label)
    
    num_zero_patches = math.floor((num_patches * (100 - percentage)) / 100)  # percentage 0-100 
    zero_patches = np.random.choice(zero_indices, size=num_zero_patches, replace=True)
    # zero_indices = list(set(zero_indices) - set(zero_patches))
    for i in zero_patches:
        img_path = os.path.join(save_path, "zero_masks", f"img_{i}.nii.gz")
        mask_path = os.path.join(save_path, "zero_masks", f"mask_{i}.nii.gz")
        label = 0
        bag["image"].append(img_path)
        bag["mask"].append(mask_path)
        bag["label"].append(label)
    
    bags.append(bag)

from test_data_set_prep import test_non_zero_img_unique
test_non_zero_img_unique(bags)

# %% Plot the patches in the bags 
# import matplotlib.pyplot as plt
# bags = bags[:10]
# fig, axes = plt.subplots(len(bags), num_patches, figsize=(10, 10))
# for i, bag in enumerate(bags):
#     for j, img_path in enumerate(bag["image"]):
#         img = nib.load(img_path).get_fdata()
#         ax = axes[i, j]
#         ax.imshow(img, cmap='gray')
#         ax.axis('off')

# plt.subplots_adjust(wspace=0.1, hspace=0.1)
# plt.show()

# fig, axes = plt.subplots(len(bags), num_patches, figsize=(10, 10))
# for i, bag in enumerate(bags):
#     for j, img_path in enumerate(bag["mask"]):
#         img = nib.load(img_path).get_fdata()
#         ax = axes[i, j]
#         ax.imshow(img, cmap='gray')
#         ax.axis('off')

# plt.subplots_adjust(wspace=0.1, hspace=0.1)
# plt.show()
# %%