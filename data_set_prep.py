# %%
import os
import yaml
import json
import argparse
import numpy as np
import nibabel as nib
import torch
import torch.cuda

#%%
def start_points(size, split_size, overlap=0):
    points = [0]
    stride = int(split_size * (1-overlap))
    counter = 1
    while True:
        pt = stride * counter
        if pt + split_size >= size:
            points.append(size - split_size)
            break
        else:
            points.append(pt)
        counter += 1
    return points


def get_tiles(h, w,
              hTile,
              wTile,
              overlap):

    '''
    Returns vectors required to sample patches from whole image
    h, w - image height, width
    hTile, wTile - patch height, width
    overlap - value in range [0-1] which stands for overlaying area of
                surrounding patches from 0 to 100% of theirs area
    '''
    X_points = start_points(w, wTile, overlap)
    Y_points = start_points(h, hTile, overlap)

    tiles = np.zeros((len(Y_points)*len(X_points), 6), int)

    k = 0
    for i, y_cord in enumerate(Y_points):
        for j, x_cord in enumerate(X_points):
            # split = image[i:i+hTile, j:j+wTile]
            tiles[k] = (y_cord, x_cord, hTile, wTile, i, j)
            k += 1
    return tiles


def convert_img_to_bag(image, tiles):
        '''
        Utilizes 'tiles' vectors generated by get_tiles function
        Returns set of patches sampled from the whole image
        '''
        hTile = tiles[0][2]
        wTile = tiles[0][3]
        c = image.shape[0]
        img_shape = (len(tiles), c, hTile, wTile)
        new_img = torch.zeros(img_shape)

        for i, tile in enumerate(tiles):
            for channel in range(c):
                new_img[i][channel] = image[channel][tile[0]:tile[0]+tile[2],
                                                     tile[1]:tile[1]+tile[3]]
            
        instances = new_img
        instances_cords = tiles[:, 4:6]

        return instances, instances_cords


def get_site_img_stats(imgs):
    '''
    Returns mean and std of the images
    '''
    img_mean = []
    img_std = []
    
    for img_path in imgs:
        img = np.asarray(nib.load(img_path).dataobj)
        mask = np.asarray(nib.load(mask_path).dataobj)
        
        img_mean.append(img.mean())
        img_std.append(img.std())

    return np.mean(img_mean), np.mean(img_std)


def get_args_parser():
    default = '/home/jr_buler/wmh/config.yml'
    help = '''path to .yml config file
    specyfying datasets/training params'''

    parser = argparse.ArgumentParser()
    parser.add_argument("--config_path", type=str,
                        default=default,
                        help=help)
    return parser

parser = get_args_parser()
args, unknown = parser.parse_known_args()
with open(args.config_path) as file:
    config = yaml.load(file, Loader=yaml.FullLoader)


#%% CONFIG load
# set seed and device
seed = config['seed']
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
patch_size = config['data_sets']['patch_size']
overlap_train_val = config['data_sets']['overlap_train_val']

overlap_train_val = 0.75


mil_params_train_val = {'patch_size': patch_size,
                        'overlap': overlap_train_val}

train_dir = config['dir']['train']

train_val_split = config['data_sets']['split_fraction_train_val']

# %% Search files in the directory
root = train_dir
brain = {"image": [], "mask": [], "brain_mask": []}

for root, dirs, files in os.walk(root, topdown=False):
    for name in files:
        f = os.path.join(root, name)

        if f.__contains__('pre/FLAIR.nii'):
            brain['image'].append(f)
            pth = os.path.join(root, 'brain_mask_bet_mask.nii.gz')
            brain['brain_mask'].append(pth)

        if f.__contains__('wmh.nii'):
            brain['mask'].append(f)

# Shuffle brain dictionary
indices = np.arange(len(brain['image']))
np.random.shuffle(indices)
train_ind, val_ind = np.split(indices, [int(train_val_split*len(indices))])

brain_train = {}
brain_val = {}

brain_train['image'] = [brain['image'][i] for i in train_ind]
brain_train['brain_mask'] = [brain['brain_mask'][i] for i in train_ind]
brain_train['mask'] = [brain['mask'][i] for i in train_ind]

brain_val['image'] = [brain['image'][i] for i in val_ind]
brain_val['brain_mask'] = [brain['brain_mask'][i] for i in val_ind]
brain_val['mask'] = [brain['mask'][i] for i in val_ind]

# %% Load images and masks, create patches and save them to the folder

for subset in {'train', 'val'}:
    save_path = '/media/dysk_a/jr_buler/WMH/patches'
    non_zero_indices = []
    zero_indices = []
    ii = 0

    if subset == 'train':
        brain = brain_train
    else:
        brain = brain_val

    save_path = os.path.join(save_path, subset)

    for i, (img_path, brain_path, mask_path) in enumerate(zip(brain['image'], brain['brain_mask'], brain['mask'])):
        img = np.asarray(nib.load(img_path).dataobj)
        mask = np.asarray(nib.load(mask_path).dataobj)
        brain = np.asarray(nib.load(brain_path).dataobj)

        tiles = get_tiles(img.shape[0],
                        img.shape[1],
                        patch_size,
                        patch_size,
                        overlap=overlap_train_val)

        img = torch.from_numpy(img)
        mask = torch.from_numpy(mask)
        brain = torch.from_numpy(brain)

        img = img.permute(2, 0, 1)    # shape [slice, h, w]
        mask = mask.permute(2, 0, 1)
        brain = brain.permute(2, 0, 1)

        img = torch.mul(img, brain, )
        
        # deleting 'other patology' mask labels
        # mask_bag[mask_bag==2.0] = 0.
        mask[mask==2.0] = 0.

        img_bag, img_coords = convert_img_to_bag(image=img,
                                                tiles=tiles)


        mask_bag, mask_coords = convert_img_to_bag(image=mask,
                                                tiles=tiles)
        
        # patch x slice x h x w -> patch*slice x h x w
        whole_img_bag = img_bag.view(-1, img_bag.shape[2], img_bag.shape[3])
        whole_mask_bag = mask_bag.view(-1, mask_bag.shape[2], mask_bag.shape[3])

        ### Discard patches under certain threshold of non-zero pixels
        patch_idx = []
        patches_to_keep = []
        for patch in range(whole_img_bag.shape[0]):
            if torch.count_nonzero(whole_img_bag[patch, :, :]) >= (0.9*patch_size**2):
                patches_to_keep.append(patch)
    
        patch_idx.append(patches_to_keep)
        whole_img_bag = whole_img_bag[patches_to_keep, :, :]
        whole_mask_bag = whole_mask_bag[patches_to_keep, :, :]
        ### Less memory required for data storage

        for img, mask in zip(whole_img_bag, whole_mask_bag):
            if torch.sum(mask) > 0:
                non_zero_indices.append(ii)
                # Save img patch to folder for non-zero masks
                folder_path = os.path.join(save_path, "non_zero_masks")
                if not os.path.exists(folder_path):
                    os.makedirs(folder_path)
                img_path = os.path.join(folder_path, f"img_{ii}.nii.gz")
                mask_path = os.path.join(folder_path, f"mask_{ii}.nii.gz")
                nib.save(nib.Nifti1Image(img.numpy(), np.eye(4)), img_path)
                # nib.save(nib.Nifti1Image(mask.numpy(), np.eye(4)), mask_path)
            else:
                zero_indices.append(ii)
                # Save img patch to folder for zero masks
                folder_path = os.path.join(save_path, "zero_masks")
                if not os.path.exists(folder_path):
                    os.makedirs(folder_path)
                img_path = os.path.join(folder_path, f"img_{ii}.nii.gz")
                mask_path = os.path.join(folder_path, f"mask_{ii}.nii.gz")
                nib.save(nib.Nifti1Image(img.numpy(), np.eye(4)), img_path)
                # nib.save(nib.Nifti1Image(mask.numpy(), np.eye(4)), mask_path)
            ii += 1

    if subset == 'train':
        non_zero_indices_train = non_zero_indices
        zero_indices_train = zero_indices
    else:
        non_zero_indices_val = non_zero_indices
        zero_indices_val = zero_indices

   
# Save non_zero_indices and zero_indices to JSON file
indices = {"non_zero_indices_train": non_zero_indices_train,
            "zero_indices_train": zero_indices_train,
            "non_zero_indices_val": non_zero_indices_val,
            "zero_indices_val": zero_indices_val}

# %%
path = '/media/dysk_a/jr_buler/WMH/patches'
json_path = os.path.join(path, "bag_info.json")
with open(json_path, "w") as json_file:
    json.dump(indices, json_file)
# %%
