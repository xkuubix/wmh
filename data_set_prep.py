# %%
import os
import yaml
import argparse
import numpy as np
import nibabel as nib
import torch
import torch.cuda
from torchvision import transforms as T

#%%
def start_points(size, split_size, overlap=0):
    points = [0]
    stride = int(split_size * (1-overlap))
    counter = 1
    while True:
        pt = stride * counter
        if pt + split_size >= size:
            points.append(size - split_size)
            break
        else:
            points.append(pt)
        counter += 1
    return points


def get_tiles(h, w,
              hTile,
              wTile,
              overlap):

    '''
    Returns vectors required to sample patches from whole image
    h, w - image height, width
    hTile, wTile - patch height, width
    overlap - value in range [0-1] which stands for overlaying area of
                surrounding patches from 0 to 100% of theirs area
    '''
    X_points = start_points(w, wTile, overlap)
    Y_points = start_points(h, hTile, overlap)

    tiles = np.zeros((len(Y_points)*len(X_points), 6), int)

    k = 0
    for i, y_cord in enumerate(Y_points):
        for j, x_cord in enumerate(X_points):
            # split = image[i:i+hTile, j:j+wTile]
            tiles[k] = (y_cord, x_cord, hTile, wTile, i, j)
            k += 1
    return tiles


def convert_img_to_bag(image, tiles):
        '''
        Utilizes 'tiles' vectors generated by get_tiles function
        Returns set of patches sampled from the whole image
        '''
        hTile = tiles[0][2]
        wTile = tiles[0][3]
        c = image.shape[0]
        img_shape = (len(tiles), c, hTile, wTile)
        new_img = torch.zeros(img_shape)

        for i, tile in enumerate(tiles):
            for channel in range(c):
                new_img[i][channel] = image[channel][tile[0]:tile[0]+tile[2],
                                                     tile[1]:tile[1]+tile[3]]
            
        instances = new_img
        instances_cords = tiles[:, 4:6]

        return instances, instances_cords


def get_site_img_stats(imgs):
    '''
    Returns mean and std of the images
    '''
    img_mean = []
    img_std = []
    
    for img_path in imgs:
        img = np.asarray(nib.load(img_path).dataobj)
        mask = np.asarray(nib.load(mask_path).dataobj)
        
        img_mean.append(img.mean())
        img_std.append(img.std())

    return np.mean(img_mean), np.mean(img_std)


def get_args_parser():
    default = '/home/jr_buler/wmh/config.yml'
    help = '''path to .yml config file
    specyfying datasets/training params'''

    parser = argparse.ArgumentParser()
    parser.add_argument("--config_path", type=str,
                        default=default,
                        help=help)
    return parser

parser = get_args_parser()
args, unknown = parser.parse_known_args()
with open(args.config_path) as file:
    config = yaml.load(file, Loader=yaml.FullLoader)


#%% CONFIG load
# set seed and device
seed = config['seed']
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
device = torch.device(config['device'] if torch.cuda.is_available() else "cpu")
# dataloaders args
train_val_frac = config['data_sets']['split_fraction_train_val']
batch_size = config['training_plan']['parameters']['batch_size']
num_workers = config['data_sets']['num_workers']
class_names = config['data_sets']['class_names']

# image parameters
patch_size = config['data_sets']['patch_size']
overlap_train_val = config['data_sets']['overlap_train_val']
overlap_test = config['data_sets']['overlap_test']

mil_params_train_val = {'patch_size': patch_size,
                        'overlap': overlap_train_val}
mil_params_test = {'patch_size': patch_size,
                   'overlap': overlap_test}

train_dir = config['dir']['train']
test_dir = config['dir']['test']

# %% Search files in the directory
root = train_dir
brain = {"image": [], "mask": [], "brain_mask": []}

for root, dirs, files in os.walk(root, topdown=False):
    for name in files:
        f = os.path.join(root, name)

        if f.__contains__('pre/FLAIR.nii'):
            brain['image'].append(f)
            pth = os.path.join(root, 'brain_mask.nii')
            brain['brain_mask'].append(pth)

        if f.__contains__('wmh.nii'):
            brain['mask'].append(f)

# %% Load images and masks, create patches and save them to the folder
for i, (img_path, mask_path) in enumerate(zip(brain['image'], brain['mask'])):
    img = np.asarray(nib.load(img_path).dataobj)
    mask = np.asarray(nib.load(mask_path).dataobj)


    '''
        TODO: brain mask
        ...
    '''

    tiles = get_tiles(img.shape[0],
                      img.shape[1],
                      patch_size,
                      patch_size,
                      overlap=0.0)
    """
        TODO:
        change overlap to var
    """
    img = torch.from_numpy(img)
    mask = torch.from_numpy(mask)
    img = img.permute(2, 0, 1)    # shape [slice, h, w]
    mask = mask.permute(2, 0, 1)
    # deleting 'other patology' mask labels
    # mask_bag[mask_bag==2.0] = 0.
    mask[mask==2.0] = 0.

    img_bag, img_coords = convert_img_to_bag(image=img,
                                               tiles=tiles)


    mask_bag, mask_coords = convert_img_to_bag(image=mask,
                                               tiles=tiles)
    
    # patch x slice x h x w -> patch*slice x h x w
    whole_img_bag = img_bag.view(-1, img_bag.shape[2], img_bag.shape[3])
    whole_mask_bag = mask_bag.view(-1, mask_bag.shape[2], mask_bag.shape[3])

    ### Discard patches under certain threshold of non-zero pixels
    patch_idx = []
    patches_to_keep = []
    for patch in range(whole_img_bag.shape[0]):
        if torch.count_nonzero(whole_img_bag[patch, :, :]) >= (0.9*patch_size**2):
  
            '''
                TODO: adjust the threshold
                ??% of the patch should be non-zero
            '''

            patches_to_keep.append(patch)
    patch_idx.append(patches_to_keep)
    whole_img_bag = whole_img_bag[patches_to_keep, :, :]
    whole_mask_bag = whole_mask_bag[patches_to_keep, :, :]
    ### Less memory required for data storage

    ii = 0
    for img, mask in zip(whole_img_bag, whole_mask_bag):
        if torch.sum(mask) > 0:
            # Save img patch to folder for non-zero masks
            folder_path = os.path.join(os.getcwd(), "non_zero_masks")
            if not os.path.exists(folder_path):
                os.makedirs(folder_path)
            img_path = os.path.join(folder_path, f"img_{ii}.nii")
            mask_path = os.path.join(folder_path, f"mask_{ii}.nii")
            nib.save(nib.Nifti1Image(img.numpy(), np.eye(4)), img_path)
            nib.save(nib.Nifti1Image(mask.numpy(), np.eye(4)), mask_path)
        else:
            # Save img patch to folder for zero masks
            folder_path = os.path.join(os.getcwd(), "zero_masks")
            if not os.path.exists(folder_path):
                os.makedirs(folder_path)
            img_path = os.path.join(folder_path, f"img_{ii}.nii")
            mask_path = os.path.join(folder_path, f"mask_{ii}.nii")
            nib.save(nib.Nifti1Image(img.numpy(), np.eye(4)), img_path)
            nib.save(nib.Nifti1Image(mask.numpy(), np.eye(4)), mask_path)
        ii += 1
   
    if i == 0:
        
        '''
            TODO:
            break delete
        '''
        
        break

# %% Create a list to store the bags
bags = []

percentages = [0, 0, 0, 0, 0, 10, 20, 30, 40, 50]
num_patches = 20

for percentage in percentages:
    num_non_zero_patches = int(percentage/100 * num_patches)
    num_zero_patches = num_patches - num_non_zero_patches
    
    non_zero_indices = [i for i, mask in enumerate(whole_mask_bag) if torch.sum(mask) > 0]
    non_zero_patches = np.random.choice(non_zero_indices, size=num_non_zero_patches, replace=False)
    bag = {"image": [], "mask": [], "label": []}
    
    for i in non_zero_patches:
        img_path = os.path.join("non_zero_masks", f"img_{i}.nii")
        mask_path = os.path.join("non_zero_masks", f"mask_{i}.nii")
        label = 1
        bag["image"].append(img_path)
        bag["mask"].append(mask_path)
        bag["label"].append(label)
    
    zero_indices = [i for i, mask in enumerate(whole_mask_bag) if torch.sum(mask) == 0]
    zero_patches = np.random.choice(zero_indices, size=num_zero_patches, replace=False)
    for i in zero_patches:
        img_path = os.path.join("zero_masks", f"img_{i}.nii")
        mask_path = os.path.join("zero_masks", f"mask_{i}.nii")
        label = 0
        bag["image"].append(img_path)
        bag["mask"].append(mask_path)
        bag["label"].append(label)
    
    bags.append(bag)

# %% Plot the patches in the bags 
import matplotlib.pyplot as plt

fig, axes = plt.subplots(len(bags), num_patches, figsize=(10, 10))
for i, bag in enumerate(bags):
    for j, img_path in enumerate(bag["image"]):
        img = nib.load(img_path).get_fdata()
        ax = axes[i, j]
        ax.imshow(img, cmap='gray')
        ax.axis('off')

plt.subplots_adjust(wspace=0.1, hspace=0.1)
plt.show()

fig, axes = plt.subplots(len(bags), num_patches, figsize=(10, 10))
for i, bag in enumerate(bags):
    for j, img_path in enumerate(bag["mask"]):
        img = nib.load(img_path).get_fdata()
        ax = axes[i, j]
        ax.imshow(img, cmap='gray')
        ax.axis('off')

plt.subplots_adjust(wspace=0.1, hspace=0.1)
plt.show()

# %%